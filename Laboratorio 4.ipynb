{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85e1c36d",
   "metadata": {},
   "source": [
    "# Laboratorio 4 Inteligencia Artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce20a13a",
   "metadata": {},
   "source": [
    "Task 1.1, leemos los archivos a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6e9d1797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Leer el archivo csv\n",
    "df = pd.read_csv('kc_house_data.csv')\n",
    "x = df['sqft_living'].values\n",
    "y = df['price'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797db0c7",
   "metadata": {},
   "source": [
    "Ahora, en orden para poder realizar el task 1.2 debemos definir la potencia con la que trabajaremos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef290a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d48d2c",
   "metadata": {},
   "source": [
    "Task 1.2 pasamos a notacion matricial los datos de x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "09cd3c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[          1,        1180,     1392400,  1643032000],\n",
       "       [          1,        2570,     6604900, 16974593000],\n",
       "       [          1,         770,      592900,   456533000],\n",
       "       ...,\n",
       "       [          1,        1020,     1040400,  1061208000],\n",
       "       [          1,        1600,     2560000,  4096000000],\n",
       "       [          1,        1020,     1040400,  1061208000]], dtype=int64)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = []\n",
    "for xi in x:\n",
    "    X.append([xi**g for g in range(0,k+1)])\n",
    "X = np.array(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77a02a1",
   "metadata": {},
   "source": [
    "Task 1.3 - 1.4\n",
    "\n",
    "Implementamos el algoritmo de cross validation junto al algoritmo de descenso de gradiente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa973b50",
   "metadata": {},
   "source": [
    "Definimos la funcion de costo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "750bdf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(X, y, theta):\n",
    "    m = len(y)\n",
    "    predictions =  np.dot(X,theta)\n",
    "    cost = np.sum((predictions-y)**2) / (2*m)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26417dae",
   "metadata": {},
   "source": [
    "Definimos los folds del algoritmo de cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d162fc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3334ae30",
   "metadata": {},
   "source": [
    "Trabajamos con los folds y desarrollamos el algoritmo de descenso de gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "cdd130a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "262112734282.11514"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = []\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    \n",
    "    # Dividir el dataset en data de entreno y test\n",
    "    X_train, y_train = X[train_idx], y[train_idx] # variables de entreno\n",
    "    X_val, y_val = X[val_idx], y[val_idx] # variables de testeo\n",
    "    \n",
    "    # Normalizar los datos de entrada\n",
    "    X_train = (X_train - np.mean(X_train)) / np.std(X_train)\n",
    "    X_val = (X_val - np.mean(X_val)) / np.std(X_val)\n",
    "\n",
    "    # Definir los parámetros del modelo y la tasa de aprendizaje\n",
    "    theta =np.random.randn(1,k+1)[0] # pesos aleatorios\n",
    "    lr = 0.0001  # tasa de aprendizaje\n",
    "    n_iterations = 1000  # número máximo de iteraciones\n",
    "\n",
    "    # Ejecutar el descenso del gradiente para encontrar los coeficientes del modelo\n",
    "    for iteration in range(n_iterations):\n",
    "        gradient = (-2*np.dot(X_train.T, y_train)) / len(y_train) # obtener el gradiente\n",
    "        theta = theta - lr * gradient # \n",
    "        cost = compute_cost(X_train, y_train, theta)\n",
    "        \n",
    "    # Obtener la perdida y la almacenamos\n",
    "    L=(np.transpose((np.subtract(y_val,X_val.dot(theta))))).dot(np.subtract(y_val,X_val.dot(theta)))\n",
    "    L = L*(1/len(X_val))\n",
    "    loss.append(L)\n",
    "\n",
    "# Operar la media de todas las perdidas almacenadas\n",
    "np.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fcd7da6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
